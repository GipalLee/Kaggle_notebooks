
데이터 타입
1. 누락된 데이터
2. 범주형 데이터 - 수치로 바꿔야함
  2.1 순서가 있음
  2.2 순서가 없음 - 원 핫 레코딩(color 속성이 있었다면 color_blue,color_red로 나누는 것) 
                    완성된 속성 중 하나를 제거할시 특성 간 상관관계를 낮출 수 있음(잃는 정보는 없음)
Overfitting - 특징이 많아서 분산
  1. 더 많은 데이터
  2. 드랍아웃
  3. 파라미터 개수 줄이기
  4. 데이터 차원 축소(잡음 제거)
  5. 규제(편향) 가중치 감쇠
  
Underfitting - 특징이 적어서 편향

  
특성 스케일
  1. 정규화(Normalization) 스케일을 0~1 사이로 만드는 행위, 이상치 민감
  2. 표준화(Standardization) 정규 분포 특징을 갖게 함, 이상치 덜 민감, 정규 분포 특징은 적은 에포크로 최적의 가중치를 찾음
 
테스트 세트와 훈련 세트 비율 
  1. 주로 6:4,7:3,8:2를 많이 사용
  2. 데이터가 대용량일 경우 9:1, 99:1도 가능

모델 튜닝 
  1. 훈련 정확도와 검증 정확도를 그래프를 그려보면 분산의 문제가 있는지 편향에 문제가 있는지 확인가능
     훈련 정확도는 위에서 검증 정확도는 아래에서 기대 정확도로 향해야 좋은 케이스
     기대 정확도에 근접하지 못하는 그래프는 높은 편향을 나타냄 - 과소 적합
     기대 정확도에 가까워 지지만 훈련 정확도와 검증 정확도의 간격이 크다면 높은 분산을 나타냄 -과대 적합


에포크
  학습을 진행해도 테스트 결과가 좋아지지 않는 시점에서 멈춰야 됨
모델 성능 평가
  1.홀드아웃 교차 검증(holdout cross-validation)
    데이터를 훈련용과 검증용 테스트용으로 나눔
  2.K-겹 교차 검증(k-fold cross-validation)
    데이터셋을 k개의 폴드로 나눔, 여러 개의 폴드로 훈련하고 한 개의 폴드로 평가하여 여러 모델의 평균 성능을 계산
